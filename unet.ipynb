{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For when doing GPU work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UNET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setting up Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'archive/Concrete/Positive/Masks/CRACK500_20160307_164517_1281_361.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(images), tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(masks)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Load positive data\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m positive_images, positive_masks \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_and_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_masks_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m448\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m448\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Load negative data\u001b[39;00m\n\u001b[1;32m     34\u001b[0m negative_images, negative_masks \u001b[38;5;241m=\u001b[39m load_images_and_masks(negative_images_dir, negative_masks_dir, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m448\u001b[39m, \u001b[38;5;241m448\u001b[39m))\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mload_images_and_masks\u001b[0;34m(images_dir, masks_dir, target_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m image \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(image) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m447.0\u001b[39m  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Load mask\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrayscale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m mask \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimg_to_array(mask) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m447.0\u001b[39m  \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[1;32m     25\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/image_utils.py:422\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[1;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive/Concrete/Positive/Masks/CRACK500_20160307_164517_1281_361.png'"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "positive_images_dir = r'archive/Concrete/Positive/Images'\n",
    "positive_masks_dir = r'archive/Concrete/Positive/Masks'\n",
    "negative_images_dir = r'archive/Concrete/Negative/Images'\n",
    "negative_masks_dir = r'archive/Concrete/Negative/Mask'\n",
    "\n",
    "# Function to load images and masks\n",
    "def load_images_and_masks(images_dir, masks_dir, target_size=(448, 448)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for filename in os.listdir(images_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img_path = os.path.join(images_dir, filename)\n",
    "            mask_path = os.path.join(masks_dir, filename.replace('.jpg', '.png'))  # Adjust if masks have different format\n",
    "            \n",
    "            # Load image\n",
    "            image = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image) / 447.0  # Normalize\n",
    "            \n",
    "            # Load mask\n",
    "            mask = tf.keras.preprocessing.image.load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
    "            mask = tf.keras.preprocessing.image.img_to_array(mask) / 447.0  # Normalize\n",
    "            \n",
    "            images.append(image)\n",
    "            masks.append(mask)\n",
    "    \n",
    "    return tf.convert_to_tensor(images), tf.convert_to_tensor(masks)\n",
    "\n",
    "# Load positive data\n",
    "positive_images, positive_masks = load_images_and_masks(positive_images_dir, positive_masks_dir, target_size=(448, 448))\n",
    "\n",
    "# Load negative data\n",
    "negative_images, negative_masks = load_images_and_masks(negative_images_dir, negative_masks_dir, target_size=(448, 448))\n",
    "\n",
    "# Combine positive and negative data\n",
    "images = tf.concat([positive_images, negative_images], axis=0)\n",
    "masks = tf.concat([positive_masks, negative_masks], axis=0)\n",
    "\n",
    "# Shuffle the combined data\n",
    "indices = tf.random.shuffle(tf.range(tf.shape(images)[0]))\n",
    "images = tf.gather(images, indices)\n",
    "masks = tf.gather(masks, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/227,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = data.shuffle(buffer_size=100, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split_size = int(len(data)*.7)\n",
    "testing_split_size = int(len(data)*.15)\n",
    "validation_split_size = int(len(data)*.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = shuffled_data.take(training_split_size)\n",
    "testing_set = shuffled_data.skip(training_split_size).take(testing_split_size)\n",
    "validation_set = shuffled_data.skip(training_split_size+testing_split_size).take(validation_split_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Buliding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)          (None, 256, 256, 64)         1792      ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)          (None, 256, 256, 64)         36928     ['conv2d_70[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooli  (None, 128, 128, 64)         0         ['conv2d_71[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)          (None, 128, 128, 128)        73856     ['max_pooling2d_20[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)          (None, 128, 128, 128)        147584    ['conv2d_72[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooli  (None, 64, 64, 128)          0         ['conv2d_73[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)          (None, 64, 64, 256)          295168    ['max_pooling2d_21[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)          (None, 64, 64, 256)          590080    ['conv2d_74[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooli  (None, 32, 32, 256)          0         ['conv2d_75[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)          (None, 32, 32, 512)          1180160   ['max_pooling2d_22[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)          (None, 32, 32, 512)          2359808   ['conv2d_76[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooli  (None, 16, 16, 512)          0         ['conv2d_77[0][0]']           \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)          (None, 16, 16, 1024)         4719616   ['max_pooling2d_23[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)          (None, 16, 16, 1024)         9438208   ['conv2d_78[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_15 (Conv2  (None, 32, 32, 512)          2097664   ['conv2d_79[0][0]']           \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 32, 32, 1024)         0         ['conv2d_transpose_15[0][0]', \n",
      " e)                                                                  'conv2d_77[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)          (None, 32, 32, 512)          4719104   ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)          (None, 32, 32, 512)          2359808   ['conv2d_80[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2  (None, 64, 64, 256)          524544    ['conv2d_81[0][0]']           \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenat  (None, 64, 64, 512)          0         ['conv2d_transpose_16[0][0]', \n",
      " e)                                                                  'conv2d_75[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)          (None, 64, 64, 256)          1179904   ['concatenate_16[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)          (None, 64, 64, 256)          590080    ['conv2d_82[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_17 (Conv2  (None, 128, 128, 128)        131200    ['conv2d_83[0][0]']           \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 128, 128, 256)        0         ['conv2d_transpose_17[0][0]', \n",
      " e)                                                                  'conv2d_73[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)          (None, 128, 128, 128)        295040    ['concatenate_17[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)          (None, 128, 128, 128)        147584    ['conv2d_84[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_18 (Conv2  (None, 256, 256, 64)         32832     ['conv2d_85[0][0]']           \n",
      " DTranspose)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenat  (None, 256, 256, 128)        0         ['conv2d_transpose_18[0][0]', \n",
      " e)                                                                  'conv2d_71[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_18[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)          (None, 256, 256, 64)         36928     ['conv2d_86[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, 256, 256, 1)          65        ['conv2d_87[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31031745 (118.38 MB)\n",
      "Trainable params: 31031745 (118.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256, 256, 3)  # Adjust based on your images\n",
    "\n",
    "# Input layer\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "# Encoder\n",
    "c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "p4 = layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "# Bottleneck\n",
    "c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "# Decoder\n",
    "u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = layers.concatenate([u6, c4])\n",
    "c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = layers.concatenate([u7, c3])\n",
    "c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = layers.concatenate([u8, c2])\n",
    "c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = layers.concatenate([u9, c1])\n",
    "c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "# Output layer\n",
    "outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)  # Use softmax for multi-class\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(training_set, epochs = 25, validation_data = validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualising Results on a sample image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize results\n",
    "def visualize_results(image, true_mask, predicted_mask):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # True mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(true_mask.squeeze(), cmap='gray')\n",
    "    plt.title('True Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Predicted mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(predicted_mask.squeeze(), cmap='gray')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Select a sample image and its true mask\n",
    "sample_index = 0  # Change this index to visualize different samples\n",
    "sample_image = images[sample_index].numpy()  # Convert tensor to numpy array\n",
    "sample_true_mask = masks[sample_index].numpy()  # Convert tensor to numpy array\n",
    "\n",
    "# Reshape for the model prediction (adding batch dimension)\n",
    "sample_image_input = np.expand_dims(sample_image, axis=0)\n",
    "\n",
    "# Predict the mask\n",
    "sample_predicted_mask = model.predict(sample_image_input)[0]  # Get the first image's prediction\n",
    "\n",
    "# Threshold the predicted mask for binary segmentation\n",
    "sample_predicted_mask = (sample_predicted_mask > 0.5).astype(np.float32)\n",
    "\n",
    "# Visualize the results\n",
    "visualize_results(sample_image, sample_true_mask, sample_predicted_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
